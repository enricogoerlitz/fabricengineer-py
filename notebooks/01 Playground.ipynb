{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a81b363a",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648232ba",
   "metadata": {},
   "source": [
    "## Initialize globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa0c3a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import io\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "from uuid import uuid4\n",
    "from typing import Any\n",
    "from contextlib import redirect_stdout\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "from fabricengineer.transform.mlv import MaterializedLakeView\n",
    "from fabricengineer.logging import TimeLogger\n",
    "\n",
    "mlv: MaterializedLakeView\n",
    "timer: TimeLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "965e651f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/31 08:51:51 WARN Utils: Your hostname, MacBook-Air-von-Enrico.local resolves to a loopback address: 127.0.0.1; using 192.168.0.3 instead (on interface en0)\n",
      "25/07/31 08:51:51 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/07/31 08:51:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "class NotebookUtilsFSMock:\n",
    "    def _get_path(self, file: str) -> str:\n",
    "        return os.path.join(os.getcwd(), file)\n",
    "\n",
    "    def exists(self, path: str) -> bool:\n",
    "        return os.path.exists(self._get_path(path))\n",
    "\n",
    "    def put(\n",
    "        self,\n",
    "        file: str,\n",
    "        content: str,\n",
    "        overwrite: bool = False\n",
    "    ) -> None:\n",
    "        path = self._get_path(file)\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "\n",
    "        if os.path.exists(path) and not overwrite:\n",
    "            raise FileExistsError(f\"File {path} already exists and overwrite is set to False.\")\n",
    "        with open(path, 'w') as f:\n",
    "            f.write(content)\n",
    "\n",
    "\n",
    "class NotebookUtilsMock:\n",
    "    def __init__(self):\n",
    "        self.fs = NotebookUtilsFSMock()\n",
    "\n",
    "global spark\n",
    "spark = SparkSession.builder.appName(\"PlaygroundSparkSession\").getOrCreate()\n",
    "\n",
    "global notebookutils\n",
    "notebookutils = NotebookUtilsMock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c6173fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sniff_logs(fn: callable) -> tuple[Any, list[str]]:\n",
    "    log_stream = io.StringIO()\n",
    "    with redirect_stdout(log_stream):\n",
    "        result = fn()\n",
    "    logs = log_stream.getvalue().splitlines()\n",
    "    return result, logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8d5599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_fs():\n",
    "    path = notebookutils.fs._get_path(\"Files\")\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "\n",
    "cleanup_fs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9d2e7c",
   "metadata": {},
   "source": [
    "## TimeLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8c8a6d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeLogger(start_time=None, end_time=None, elapsed_time=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../src/fabricengineer/logging/timer.py\") as f:\n",
    "    code = f.read()\n",
    "exec(code, globals())\n",
    "\n",
    "timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30d295e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMER-START:\t2025-07-31 08:51:52\n",
      "TIMER-END:\t2025-07-31 08:51:53, ELAPSED: 1.0152s\n"
     ]
    }
   ],
   "source": [
    "timer.start().log()\n",
    "time.sleep(1)\n",
    "timer.stop().log()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0076f2b1",
   "metadata": {},
   "source": [
    "## MaterializedLakeView"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba1bbfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lakehouse': 'Lakehouse',\n",
       " 'schema': 'schema',\n",
       " 'table': 'table',\n",
       " 'table_path': 'Lakehouse.schema.table'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../src/fabricengineer/transform/mlv/mlv.py\") as f:\n",
    "    code = f.read()\n",
    "exec(code, globals())\n",
    "\n",
    "\n",
    "mlv.init(\n",
    "    lakehouse=\"Lakehouse\",\n",
    "    schema=\"schema\",\n",
    "    table=\"table\",\n",
    "    table_suffix=None,\n",
    "    is_testing_mock=True\n",
    ")\n",
    "\n",
    "mlv.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "85d270d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logs-1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Mock: CREATE SCHEMA 1cadbe22-0267-4a1a-a8cb-91b04335b1df.schema',\n",
       " 'Mock: CREATE MLV 1cadbe22-0267-4a1a-a8cb-91b04335b1df.schema.table']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logs-2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Nothing has changed']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logs-3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['REPLACE MLV: 1cadbe22-0267-4a1a-a8cb-91b04335b1df.schema.table',\n",
       " 'Mock: DROP MLV 1cadbe22-0267-4a1a-a8cb-91b04335b1df.schema.table',\n",
       " 'Mock: CREATE SCHEMA 1cadbe22-0267-4a1a-a8cb-91b04335b1df.schema',\n",
       " 'Mock: CREATE MLV 1cadbe22-0267-4a1a-a8cb-91b04335b1df.schema.table']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logs-4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Nothing has changed']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlv.init(\n",
    "    lakehouse=str(uuid4()),\n",
    "    schema=\"schema\",\n",
    "    table=\"table\",\n",
    "    table_suffix=None,\n",
    "    is_testing_mock=True\n",
    ")\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT * FROM Lakehouse.schema.table\n",
    "\"\"\"\n",
    "is_existing = False\n",
    "for i in range(0, 4):\n",
    "    if i > 0:\n",
    "        is_existing = True\n",
    "    if i == 2:\n",
    "        sql = \"\"\"\n",
    "        SELECT * FROM Lakehouse.schema.table WHERE 1=0\n",
    "        \"\"\"\n",
    "    result, logs = sniff_logs(\n",
    "        lambda: mlv.create_or_replace(sql, mock_is_existing=is_existing)\n",
    "    )\n",
    "    print(f\"Logs-{i+1}\")\n",
    "    display(logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a6be1e",
   "metadata": {},
   "source": [
    "## Clean up the file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4c8f3764",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup_fs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
